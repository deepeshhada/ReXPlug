{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NCF - Review Regularizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtIfarCnnjHE",
        "outputId": "afc26cf8-a8bf-471d-d75c-d62791ff74ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import string\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "tokenize = gensim.utils.simple_preprocess\n",
        "sym = list(string.punctuation)\n",
        "stop_words = set(stopwords.words(\"english\")) | set([\"br\"]) | set(sym) | set([\"/><br\",'\\'s'])\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 256\n",
        "num_factors = 16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm64_Mt6nq39"
      },
      "source": [
        "dataset_name = \"AmazonLuxuryBeauty\"\n",
        "splits_ready = False\n",
        "data_path = '/content/drive/My Drive/Colab Data/M.Tech. Project/datasets/Amazon/' + dataset_name + \"/\" + dataset_name + \".zip\"\n",
        "save_path = \"./drive/My Drive/Colab Data/M.Tech. Project/saved splits/Amazon/\" + dataset_name + \"/\"\n",
        "\n",
        "with zipfile.ZipFile(data_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/data/\" + dataset_name + \"/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvdJmEPGoQvg"
      },
      "source": [
        "df = pd.read_json(\"/content/data/\" + dataset_name + \"/\" + dataset_name + \".json\", lines=True)\n",
        "df = df[['reviewerID', 'asin', 'reviewText', 'overall']]\n",
        "columns = ['userId', 'itemId', 'review', 'rating']\n",
        "df.columns = columns\n",
        "num_users = len(df['userId'].unique())\n",
        "num_items = len(df['itemId'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31U8hso3Xpp1"
      },
      "source": [
        "def process_text(text):\n",
        "    processed = \" \".join(\n",
        "        [token for token in tokenize(text)\n",
        "            if token not in stop_words and len(token) > 2]\n",
        "    )\n",
        "    return processed\n",
        "\n",
        "def generate_splits(df):\n",
        "    train_df, test_df = train_test_split(df, test_size=0.2)\n",
        "    val_df, test_df = train_test_split(test_df, test_size=0.5)\n",
        "    return (train_df, val_df, test_df)\n",
        "\n",
        "\n",
        "def get_embeddings(reviews, load=True):\n",
        "    if load:\n",
        "        with open(save_path + 'true_sentence_embeddings.pkl', 'rb') as f:\n",
        "            true_embeddings = pickle.load(f)\n",
        "    else:\n",
        "        reviews = reviews.tolist()\n",
        "        true_embeddings = []\n",
        "        for review in reviews:\n",
        "            embeddings = embed([review]).numpy()\n",
        "            true_embeddings.append(embeddings)\n",
        "        true_embeddings = np.array(true_embeddings).squeeze()\n",
        "        with open(save_path + 'true_sentence_embeddings.pkl', 'wb') as f:\n",
        "            pickle.dump(true_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
        "    return true_embeddings\n",
        "\n",
        "\n",
        "def create_dataset(df, mode=\"Test\"):\n",
        "    user_item_ratings = {}\n",
        "    if mode == \"Train\":\n",
        "        for idx, row in df.iterrows():\n",
        "            user_item_ratings[idx] = [int(row[0]), int(row[1]), true_embeddings[idx], row[3]]\n",
        "    else:\n",
        "        for idx, row in df.iterrows():\n",
        "            user_item_ratings[idx] = [int(row[0]), int(row[1]), row[3]]\n",
        "    return user_item_ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9TnNdt9AnK4",
        "outputId": "97f7ffc1-6ee3-4b7b-9db2-7d4b42b41719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "if not splits_ready:\n",
        "    df = df[~df['review'].isna()]\n",
        "    df['review'] = df['review'].apply(lambda review: process_text(review))\n",
        "    df = df[~df['review'].isna()]\n",
        "    df = df.sample(frac=1)\n",
        "    \n",
        "    df['userId'] = df['userId'].astype('category').cat.codes\n",
        "    df['itemId'] = df['itemId'].astype('category').cat.codes\n",
        "    \n",
        "    train_df, val_df, test_df = generate_splits(df)\n",
        "    print(f\"Train size: {len(train_df)} | Val size: {len(val_df)} | Test size: {len(test_df)}\")\n",
        "\n",
        "    df.to_csv(save_path + 'df.csv', index=False)\n",
        "    train_df.to_csv(save_path + 'train_df.csv', index=False)\n",
        "    val_df.to_csv(save_path + 'val_df.csv', index=False)\n",
        "    test_df.to_csv(save_path + 'test_df.csv', index=False)\n",
        "else:\n",
        "    df = pd.read_csv(save_path + 'df.csv')\n",
        "    train_df = pd.read_csv(save_path + 'train_df.csv')\n",
        "    val_df = pd.read_csv(save_path + 'val_df.csv')\n",
        "    test_df = pd.read_csv(save_path + 'test_df.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 27412 | Val size: 3426 | Test size: 3427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0go9wfoboZA9",
        "outputId": "230ecbc3-496e-4cbc-9cfe-400e201cede7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "df = pd.read_csv(save_path + 'df.csv')\n",
        "train_df = pd.read_csv(save_path + 'train_df.csv')\n",
        "val_df = pd.read_csv(save_path + 'val_df.csv')\n",
        "test_df = pd.read_csv(save_path + 'test_df.csv')\n",
        "\n",
        "df = df[~df['review'].isna()].reset_index(drop=True)\n",
        "train_df = train_df[~train_df['review'].isna()].reset_index(drop=True)\n",
        "val_df = val_df[~val_df['review'].isna()].reset_index(drop=True)\n",
        "test_df = test_df[~test_df['review'].isna()].reset_index(drop=True)\n",
        "\n",
        "true_embeddings = get_embeddings(train_df[\"review\"], load=splits_ready)\n",
        "print(f\"Train size: {len(train_df)} | Val size: {len(val_df)} | Test size: {len(test_df)}\")\n",
        "\n",
        "train_set = create_dataset(train_df, mode=\"Train\")\n",
        "val_set = create_dataset(val_df, mode=\"Val\")\n",
        "test_set = create_dataset(test_df, mode=\"Test\")\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 27386 | Val size: 3422 | Test size: 3427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXf3EdI_FFrV"
      },
      "source": [
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    mse_fn = nn.MSELoss()\n",
        "    mae_fn = nn.L1Loss()\n",
        "\n",
        "    for user_item_rating in data_loader:\n",
        "        users, items, ratings = user_item_rating\n",
        "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
        "        preds = model(users, items)\n",
        "        ratings = ratings.float().view(preds[0].size())\n",
        "        mse = mse_fn(preds[0], ratings)\n",
        "        mae = mae_fn(preds[0], ratings)\n",
        "    \n",
        "    return mse.item(), mae.item()\n",
        "    \n",
        "\n",
        "def train_one_epoch(model, data_loader, loss_function, optimizer, epoch):\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "    epoch_loss1 = []\n",
        "    epoch_loss2 = []\n",
        "    decay = 5\n",
        "\n",
        "    for user_item_rating in data_loader:\n",
        "        users, items, reviews, ratings = user_item_rating\n",
        "        users, items, reviews, ratings = users.to(device), items.to(device), reviews.to(device), ratings.to(device)\n",
        "        preds = model(users, items, reviews)\n",
        "        ratings = ratings.float().view(preds[0].size())\n",
        "        loss1 = loss_function(preds[0], ratings)\n",
        "        loss2 = decay*loss_function(preds[1], reviews)\n",
        "        loss = loss1 + loss2\n",
        "        # loss = loss1\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss.append(loss.item())\n",
        "        epoch_loss1.append(loss1.item())\n",
        "        epoch_loss2.append(loss2.item())\n",
        "\n",
        "    epoch_loss = np.mean(epoch_loss)\n",
        "    epoch_loss1 = np.mean(epoch_loss1)\n",
        "    epoch_loss2 = np.mean(epoch_loss2)\n",
        "    val_mse, val_mae = evaluate(model, val_loader)\n",
        "    print(f\"Epoch: {epoch} | Train MSE: {epoch_loss}\")\n",
        "    print(f\"\\t Model MSE: {epoch_loss1} | Regularizer MSE: {epoch_loss2} \")\n",
        "    print(f\"\\t Val MSE: {val_mse} | Val MAE: {val_mae} \")\n",
        "    return epoch_loss, epoch_loss1, epoch_loss2, val_mse, val_mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0XMkuUoYXuy"
      },
      "source": [
        "num_factors = 16\n",
        "\n",
        "class ReviewRegularizer(nn.Module):\n",
        "    def __init__(self, num_factors, num_layers=1):\n",
        "        super(ReviewRegularizer, self).__init__()\n",
        "        modules = []\n",
        "        input_size = 128\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Dropout(p=0.7),\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, interaction):\n",
        "        output = self.model(interaction)\n",
        "        return output\n",
        "\n",
        "\n",
        "class NCF(nn.Module):\n",
        "    def __init__(self, review_regularizer, num_users, num_items, num_factors=16, num_layers=4):\n",
        "        super(NCF, self).__init__()\n",
        "\n",
        "        embed_dim = num_factors * (2 ** (num_layers - 1))\n",
        "        self.embed_user_MLP = nn.Embedding(num_embeddings=num_users, embedding_dim=embed_dim)\n",
        "        self.embed_item_MLP = nn.Embedding(num_embeddings=num_items, embedding_dim=embed_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        MLP_modules = []\n",
        "        for i in range(num_layers):\n",
        "            input_size = num_factors * (2 ** (num_layers - i))\n",
        "            MLP_modules.append(nn.Dropout(p=0.4))\n",
        "            MLP_modules.append(nn.Linear(input_size, input_size//2))\n",
        "            MLP_modules.append(nn.ReLU())\n",
        "        self.MLP_forward = nn.Sequential(*MLP_modules)\n",
        "        predict_size = num_factors\n",
        "        self.predict = nn.Linear(predict_size, 1)\n",
        "\n",
        "        self.review_regularizer = review_regularizer\n",
        "\n",
        "    def forward(self, user, item, review=None):\n",
        "        embed_user_MLP = self.embed_user_MLP(user)\n",
        "        embed_item_MLP = self.embed_item_MLP(item)\n",
        "        interaction = torch.cat((embed_user_MLP, embed_item_MLP), -1)\n",
        "        output_MLP = self.MLP_forward(self.dropout(interaction))\n",
        "        preds = []\n",
        "        preds.append(self.predict(output_MLP).view(-1))\n",
        "\n",
        "        if review is not None:\n",
        "            regularizer = self.review_regularizer(interaction)\n",
        "            preds.append(regularizer)\n",
        "\n",
        "        return preds\n",
        "\n",
        "\n",
        "review_regularizer = ReviewRegularizer(num_factors=num_factors).to(device)\n",
        "model = NCF(review_regularizer, num_users, num_items, num_factors=num_factors, num_layers=3).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "num_epochs = 80\n",
        "losses = []\n",
        "losses1 = []\n",
        "losses2 = []\n",
        "val_mses = []\n",
        "val_maes = []\n",
        "best_val_mse = 100\n",
        "best_model = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9BoIyE-3XpI",
        "outputId": "68b0e81e-7e01-428e-9d9f-bf06c3910cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(1, num_epochs + 1):\n",
        "    epoch_loss, epoch_loss1, epoch_loss2, val_mse, val_mae = train_one_epoch(\n",
        "        model=model, \n",
        "        data_loader=train_loader, \n",
        "        loss_function=loss_function, \n",
        "        optimizer=optimizer, \n",
        "        epoch=epoch\n",
        "    )\n",
        "    if val_mse < best_val_mse:\n",
        "        best_val_mse = val_mse\n",
        "        best_model = model\n",
        "        torch.save(model.state_dict(), \"./model.pth\")\n",
        "        print(\"Saving model...\")\n",
        "    losses.append(epoch_loss)\n",
        "    losses1.append(epoch_loss1)\n",
        "    losses2.append(epoch_loss2)\n",
        "    val_mses.append(val_mse)\n",
        "    val_maes.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Train MSE: 8.225450836609458\n",
            "\t Model MSE: 6.975387682424527 | Regularizer MSE: 1.2500631096207093 \n",
            "\t Val MSE: 4.945785045623779 | Val MAE: 2.0940771102905273 \n",
            "Saving model...\n",
            "Epoch: 2 | Train MSE: 3.4267347193209923\n",
            "\t Model MSE: 2.4478197632548966 | Regularizer MSE: 0.9789149460391463 \n",
            "\t Val MSE: 4.141963958740234 | Val MAE: 1.9140702486038208 \n",
            "Saving model...\n",
            "Epoch: 3 | Train MSE: 3.0895324889744553\n",
            "\t Model MSE: 2.2390713836545144 | Regularizer MSE: 0.8504611008635191 \n",
            "\t Val MSE: 3.7900052070617676 | Val MAE: 1.8158149719238281 \n",
            "Saving model...\n",
            "Epoch: 4 | Train MSE: 2.8413227228360753\n",
            "\t Model MSE: 2.0929287237541696 | Regularizer MSE: 0.7483939879408507 \n",
            "\t Val MSE: 3.093989849090576 | Val MAE: 1.62710440158844 \n",
            "Saving model...\n",
            "Epoch: 5 | Train MSE: 2.614825914953357\n",
            "\t Model MSE: 1.9537305486536471 | Regularizer MSE: 0.6610953713131842 \n",
            "\t Val MSE: 2.810434341430664 | Val MAE: 1.5310927629470825 \n",
            "Saving model...\n",
            "Epoch: 6 | Train MSE: 2.419850898680286\n",
            "\t Model MSE: 1.830698177079174 | Regularizer MSE: 0.5891527132453206 \n",
            "\t Val MSE: 2.3693976402282715 | Val MAE: 1.3854901790618896 \n",
            "Saving model...\n",
            "Epoch: 7 | Train MSE: 2.2013118222495107\n",
            "\t Model MSE: 1.6802593937544066 | Regularizer MSE: 0.5210524184681545 \n",
            "\t Val MSE: 1.7685904502868652 | Val MAE: 1.1972277164459229 \n",
            "Saving model...\n",
            "Epoch: 8 | Train MSE: 1.996678566264215\n",
            "\t Model MSE: 1.5380160507754745 | Regularizer MSE: 0.4586625090826338 \n",
            "\t Val MSE: 1.3876937627792358 | Val MAE: 1.0631065368652344 \n",
            "Saving model...\n",
            "Epoch: 9 | Train MSE: 1.814891314952173\n",
            "\t Model MSE: 1.4044613258860936 | Regularizer MSE: 0.4104299857237629 \n",
            "\t Val MSE: 0.9880588054656982 | Val MAE: 0.8407698273658752 \n",
            "Saving model...\n",
            "Epoch: 10 | Train MSE: 1.6699897251396536\n",
            "\t Model MSE: 1.3048175083142575 | Regularizer MSE: 0.36517222128181814 \n",
            "\t Val MSE: 0.9180924892425537 | Val MAE: 0.7980605363845825 \n",
            "Saving model...\n",
            "Epoch: 11 | Train MSE: 1.5801392348013192\n",
            "\t Model MSE: 1.252107774542871 | Regularizer MSE: 0.3280314622081329 \n",
            "\t Val MSE: 0.8951109051704407 | Val MAE: 0.7903346419334412 \n",
            "Saving model...\n",
            "Epoch: 12 | Train MSE: 1.515472634930477\n",
            "\t Model MSE: 1.2220517926126997 | Regularizer MSE: 0.293420840646619 \n",
            "\t Val MSE: 0.9112621545791626 | Val MAE: 0.7951385378837585 \n",
            "Epoch: 13 | Train MSE: 1.4427799621475077\n",
            "\t Model MSE: 1.178480645206487 | Regularizer MSE: 0.2642993207011267 \n",
            "\t Val MSE: 0.8592606782913208 | Val MAE: 0.778643012046814 \n",
            "Saving model...\n",
            "Epoch: 14 | Train MSE: 1.3919538705148429\n",
            "\t Model MSE: 1.1532885393249654 | Regularizer MSE: 0.2386653275690346 \n",
            "\t Val MSE: 0.847967803478241 | Val MAE: 0.7725636959075928 \n",
            "Saving model...\n",
            "Epoch: 15 | Train MSE: 1.3476355788863708\n",
            "\t Model MSE: 1.130443045469088 | Regularizer MSE: 0.21719253216391413 \n",
            "\t Val MSE: 0.8430925607681274 | Val MAE: 0.7697544097900391 \n",
            "Saving model...\n",
            "Epoch: 16 | Train MSE: 1.314099914559694\n",
            "\t Model MSE: 1.1176087811728503 | Regularizer MSE: 0.19649112893042164 \n",
            "\t Val MSE: 0.8564801812171936 | Val MAE: 0.7766483426094055 \n",
            "Epoch: 17 | Train MSE: 1.2818836865024033\n",
            "\t Model MSE: 1.1029907682231654 | Regularizer MSE: 0.17889291591176362 \n",
            "\t Val MSE: 0.8545507788658142 | Val MAE: 0.7743322253227234 \n",
            "Epoch: 18 | Train MSE: 1.2621957214079171\n",
            "\t Model MSE: 1.0985352179714452 | Regularizer MSE: 0.16366050482910371 \n",
            "\t Val MSE: 0.834371030330658 | Val MAE: 0.7617273330688477 \n",
            "Saving model...\n",
            "Epoch: 19 | Train MSE: 1.238887705535532\n",
            "\t Model MSE: 1.0881191820741813 | Regularizer MSE: 0.15076852346135078 \n",
            "\t Val MSE: 0.8554887175559998 | Val MAE: 0.7748112678527832 \n",
            "Epoch: 20 | Train MSE: 1.2213855591889853\n",
            "\t Model MSE: 1.0822742391969555 | Regularizer MSE: 0.13911132173281965 \n",
            "\t Val MSE: 0.8140421509742737 | Val MAE: 0.7466973662376404 \n",
            "Saving model...\n",
            "Epoch: 21 | Train MSE: 1.2098942577281846\n",
            "\t Model MSE: 1.0817130319425994 | Regularizer MSE: 0.12818122808342783 \n",
            "\t Val MSE: 0.8501651287078857 | Val MAE: 0.7711141705513 \n",
            "Epoch: 22 | Train MSE: 1.1934555089362313\n",
            "\t Model MSE: 1.0750847169171984 | Regularizer MSE: 0.11837079529171791 \n",
            "\t Val MSE: 0.8214484453201294 | Val MAE: 0.7541984915733337 \n",
            "Epoch: 23 | Train MSE: 1.1823682840739456\n",
            "\t Model MSE: 1.0714717278970736 | Regularizer MSE: 0.11089656314003134 \n",
            "\t Val MSE: 0.798393726348877 | Val MAE: 0.7338836193084717 \n",
            "Saving model...\n",
            "Epoch: 24 | Train MSE: 1.1666343418237204\n",
            "\t Model MSE: 1.0625552585191815 | Regularizer MSE: 0.10407908643796066 \n",
            "\t Val MSE: 0.7861762642860413 | Val MAE: 0.7284887433052063 \n",
            "Saving model...\n",
            "Epoch: 25 | Train MSE: 1.1542781335171137\n",
            "\t Model MSE: 1.0566946000696342 | Regularizer MSE: 0.09758353442232186 \n",
            "\t Val MSE: 0.7641263604164124 | Val MAE: 0.7125083804130554 \n",
            "Saving model...\n",
            "Epoch: 26 | Train MSE: 1.132970599370582\n",
            "\t Model MSE: 1.0413551999029713 | Regularizer MSE: 0.09161540134766391 \n",
            "\t Val MSE: 0.7360013127326965 | Val MAE: 0.6742640733718872 \n",
            "Saving model...\n",
            "Epoch: 27 | Train MSE: 1.1143071021989128\n",
            "\t Model MSE: 1.0277580451742512 | Regularizer MSE: 0.08654905556239814 \n",
            "\t Val MSE: 0.7059879302978516 | Val MAE: 0.6826324462890625 \n",
            "Saving model...\n",
            "Epoch: 28 | Train MSE: 1.0739534870486394\n",
            "\t Model MSE: 0.9920190143808026 | Regularizer MSE: 0.0819344750353109 \n",
            "\t Val MSE: 0.6813992857933044 | Val MAE: 0.6621173024177551 \n",
            "Saving model...\n",
            "Epoch: 29 | Train MSE: 1.032961911687227\n",
            "\t Model MSE: 0.954094694039532 | Regularizer MSE: 0.07886721904032698 \n",
            "\t Val MSE: 0.6432083249092102 | Val MAE: 0.6139395236968994 \n",
            "Saving model...\n",
            "Epoch: 30 | Train MSE: 0.9782419694918338\n",
            "\t Model MSE: 0.9024516984681102 | Regularizer MSE: 0.07579027011851285 \n",
            "\t Val MSE: 0.618287980556488 | Val MAE: 0.5995067954063416 \n",
            "Saving model...\n",
            "Epoch: 31 | Train MSE: 0.9339049887434344\n",
            "\t Model MSE: 0.8611442697382419 | Regularizer MSE: 0.07276071924890314 \n",
            "\t Val MSE: 0.6130887269973755 | Val MAE: 0.5718590617179871 \n",
            "Saving model...\n",
            "Epoch: 32 | Train MSE: 0.9127412293558923\n",
            "\t Model MSE: 0.8427348610396698 | Regularizer MSE: 0.07000636810732778 \n",
            "\t Val MSE: 0.6046341061592102 | Val MAE: 0.5599244832992554 \n",
            "Saving model...\n",
            "Epoch: 33 | Train MSE: 0.8741707150067124\n",
            "\t Model MSE: 0.8059221355714531 | Regularizer MSE: 0.0682485779033643 \n",
            "\t Val MSE: 0.6265918612480164 | Val MAE: 0.5868398547172546 \n",
            "Epoch: 34 | Train MSE: 0.8507316664000538\n",
            "\t Model MSE: 0.784281529555811 | Regularizer MSE: 0.06645014077842792 \n",
            "\t Val MSE: 0.6147624850273132 | Val MAE: 0.5647363066673279 \n",
            "Epoch: 35 | Train MSE: 0.8313732397890536\n",
            "\t Model MSE: 0.7658335839476541 | Regularizer MSE: 0.06553965563250479 \n",
            "\t Val MSE: 0.614460289478302 | Val MAE: 0.5830525755882263 \n",
            "Epoch: 36 | Train MSE: 0.8093098702831804\n",
            "\t Model MSE: 0.745366521527834 | Regularizer MSE: 0.06394334687529324 \n",
            "\t Val MSE: 0.5991323590278625 | Val MAE: 0.5568364858627319 \n",
            "Saving model...\n",
            "Epoch: 37 | Train MSE: 0.7884966318852433\n",
            "\t Model MSE: 0.7258392043202837 | Regularizer MSE: 0.06265742665974894 \n",
            "\t Val MSE: 0.6155586242675781 | Val MAE: 0.5753291249275208 \n",
            "Epoch: 38 | Train MSE: 0.7769368719831805\n",
            "\t Model MSE: 0.7153672503533764 | Regularizer MSE: 0.06156962256983062 \n",
            "\t Val MSE: 0.6164273023605347 | Val MAE: 0.5609427094459534 \n",
            "Epoch: 39 | Train MSE: 0.7597361680503204\n",
            "\t Model MSE: 0.6987694248417827 | Regularizer MSE: 0.06096674341743238 \n",
            "\t Val MSE: 0.6008410453796387 | Val MAE: 0.5522672533988953 \n",
            "Epoch: 40 | Train MSE: 0.749666995534273\n",
            "\t Model MSE: 0.6891251011429546 | Regularizer MSE: 0.060541891536422976 \n",
            "\t Val MSE: 0.6215294599533081 | Val MAE: 0.5909729599952698 \n",
            "Epoch: 41 | Train MSE: 0.7312280881070645\n",
            "\t Model MSE: 0.6710373413897006 | Regularizer MSE: 0.06019074727441663 \n",
            "\t Val MSE: 0.6209113597869873 | Val MAE: 0.5866469144821167 \n",
            "Epoch: 42 | Train MSE: 0.7258060167883044\n",
            "\t Model MSE: 0.6663967811058615 | Regularizer MSE: 0.05940923589133771 \n",
            "\t Val MSE: 0.6034937500953674 | Val MAE: 0.5415045619010925 \n",
            "Epoch: 43 | Train MSE: 0.7094995304245815\n",
            "\t Model MSE: 0.6503953318172526 | Regularizer MSE: 0.05910419846806571 \n",
            "\t Val MSE: 0.6134670376777649 | Val MAE: 0.5651755332946777 \n",
            "Epoch: 44 | Train MSE: 0.6963607874986167\n",
            "\t Model MSE: 0.637832385914348 | Regularizer MSE: 0.05852840245466366 \n",
            "\t Val MSE: 0.6080309152603149 | Val MAE: 0.5699110627174377 \n",
            "Epoch: 45 | Train MSE: 0.6935923951808537\n",
            "\t Model MSE: 0.6350061077380849 | Regularizer MSE: 0.058586287721295226 \n",
            "\t Val MSE: 0.6052803993225098 | Val MAE: 0.5482909083366394 \n",
            "Epoch: 46 | Train MSE: 0.6789291634737888\n",
            "\t Model MSE: 0.6206849381745418 | Regularizer MSE: 0.058244224463667824 \n",
            "\t Val MSE: 0.6040730476379395 | Val MAE: 0.563805103302002 \n",
            "Epoch: 47 | Train MSE: 0.6719778336097146\n",
            "\t Model MSE: 0.613675621625419 | Regularizer MSE: 0.05830221160132194 \n",
            "\t Val MSE: 0.6026767492294312 | Val MAE: 0.5695282220840454 \n",
            "Epoch: 48 | Train MSE: 0.661107023464185\n",
            "\t Model MSE: 0.6031197111740291 | Regularizer MSE: 0.057987309748602806 \n",
            "\t Val MSE: 0.5807170867919922 | Val MAE: 0.5454156398773193 \n",
            "Saving model...\n",
            "Epoch: 49 | Train MSE: 0.6541901537191088\n",
            "\t Model MSE: 0.5965623312464384 | Regularizer MSE: 0.05762782289045994 \n",
            "\t Val MSE: 0.5913578867912292 | Val MAE: 0.5491566061973572 \n",
            "Epoch: 50 | Train MSE: 0.6479810732547368\n",
            "\t Model MSE: 0.5901018074739759 | Regularizer MSE: 0.05787926376144463 \n",
            "\t Val MSE: 0.589705228805542 | Val MAE: 0.5546334981918335 \n",
            "Epoch: 51 | Train MSE: 0.6395114816237832\n",
            "\t Model MSE: 0.5815238718674561 | Regularizer MSE: 0.057987609825958714 \n",
            "\t Val MSE: 0.5886481404304504 | Val MAE: 0.5464099049568176 \n",
            "Epoch: 52 | Train MSE: 0.6339540609689517\n",
            "\t Model MSE: 0.5763352984022871 | Regularizer MSE: 0.05761876200961175 \n",
            "\t Val MSE: 0.5932400226593018 | Val MAE: 0.548762321472168 \n",
            "Epoch: 53 | Train MSE: 0.6306611324582144\n",
            "\t Model MSE: 0.5730111314871601 | Regularizer MSE: 0.057649999299896094 \n",
            "\t Val MSE: 0.621451199054718 | Val MAE: 0.5693340301513672 \n",
            "Epoch: 54 | Train MSE: 0.6223296495241539\n",
            "\t Model MSE: 0.5648417353073013 | Regularizer MSE: 0.05748791759398496 \n",
            "\t Val MSE: 0.6202796697616577 | Val MAE: 0.5407211780548096 \n",
            "Epoch: 55 | Train MSE: 0.6161295935929378\n",
            "\t Model MSE: 0.5585670376492438 | Regularizer MSE: 0.05756255322806189 \n",
            "\t Val MSE: 0.6093278527259827 | Val MAE: 0.5555150508880615 \n",
            "Epoch: 56 | Train MSE: 0.615893755282197\n",
            "\t Model MSE: 0.5581592956436014 | Regularizer MSE: 0.05773445949933239 \n",
            "\t Val MSE: 0.6015082597732544 | Val MAE: 0.5480301976203918 \n",
            "Epoch: 57 | Train MSE: 0.6105682393100774\n",
            "\t Model MSE: 0.5530455900686924 | Regularizer MSE: 0.05752265028585898 \n",
            "\t Val MSE: 0.6109474301338196 | Val MAE: 0.5608841776847839 \n",
            "Epoch: 58 | Train MSE: 0.5998516183033168\n",
            "\t Model MSE: 0.5422610743580577 | Regularizer MSE: 0.05759054436304859 \n",
            "\t Val MSE: 0.6256759762763977 | Val MAE: 0.565136730670929 \n",
            "Epoch: 59 | Train MSE: 0.600073026440968\n",
            "\t Model MSE: 0.5424564753737405 | Regularizer MSE: 0.057616548734569104 \n",
            "\t Val MSE: 0.6158613562583923 | Val MAE: 0.5491747856140137 \n",
            "Epoch: 60 | Train MSE: 0.5917257376920397\n",
            "\t Model MSE: 0.5341119111698365 | Regularizer MSE: 0.057613827218519195 \n",
            "\t Val MSE: 0.604839563369751 | Val MAE: 0.5387365818023682 \n",
            "Epoch: 61 | Train MSE: 0.5915731642847863\n",
            "\t Model MSE: 0.533878516371005 | Regularizer MSE: 0.057694649236781574 \n",
            "\t Val MSE: 0.6163402795791626 | Val MAE: 0.5481396317481995 \n",
            "Epoch: 62 | Train MSE: 0.5843812015569099\n",
            "\t Model MSE: 0.5265486073271136 | Regularizer MSE: 0.05783259443869101 \n",
            "\t Val MSE: 0.5951311588287354 | Val MAE: 0.5508458614349365 \n",
            "Epoch: 63 | Train MSE: 0.5860093539563295\n",
            "\t Model MSE: 0.5284131442275003 | Regularizer MSE: 0.05759621025106617 \n",
            "\t Val MSE: 0.5907586812973022 | Val MAE: 0.5483571290969849 \n",
            "Epoch: 64 | Train MSE: 0.5737439098759233\n",
            "\t Model MSE: 0.5160316362559239 | Regularizer MSE: 0.05771227309776244 \n",
            "\t Val MSE: 0.6031238436698914 | Val MAE: 0.5610043406486511 \n",
            "Epoch: 65 | Train MSE: 0.5759909036003541\n",
            "\t Model MSE: 0.5182731917528348 | Regularizer MSE: 0.057717711464545435 \n",
            "\t Val MSE: 0.5948466658592224 | Val MAE: 0.5498717427253723 \n",
            "Epoch: 66 | Train MSE: 0.5705846135861405\n",
            "\t Model MSE: 0.5129325336942049 | Regularizer MSE: 0.05765208145864656 \n",
            "\t Val MSE: 0.6067605018615723 | Val MAE: 0.554466962814331 \n",
            "Epoch: 67 | Train MSE: 0.5691751770884077\n",
            "\t Model MSE: 0.5111436370377228 | Regularizer MSE: 0.058031538762500355 \n",
            "\t Val MSE: 0.6095749139785767 | Val MAE: 0.5589249730110168 \n",
            "Epoch: 68 | Train MSE: 0.5670791755769854\n",
            "\t Model MSE: 0.5093614679073619 | Regularizer MSE: 0.057717707808886735 \n",
            "\t Val MSE: 0.5978720188140869 | Val MAE: 0.560016393661499 \n",
            "Epoch: 69 | Train MSE: 0.563593296247108\n",
            "\t Model MSE: 0.5056407560254926 | Regularizer MSE: 0.05795254098756291 \n",
            "\t Val MSE: 0.59902024269104 | Val MAE: 0.5600225925445557 \n",
            "Epoch: 70 | Train MSE: 0.5531042301766226\n",
            "\t Model MSE: 0.49517901645642576 | Regularizer MSE: 0.05792521365056528 \n",
            "\t Val MSE: 0.5967841148376465 | Val MAE: 0.5651541352272034 \n",
            "Epoch: 71 | Train MSE: 0.5479969775008264\n",
            "\t Model MSE: 0.4900463042415191 | Regularizer MSE: 0.0579506744082286 \n",
            "\t Val MSE: 0.6017123460769653 | Val MAE: 0.5624216794967651 \n",
            "Epoch: 72 | Train MSE: 0.5540832573565367\n",
            "\t Model MSE: 0.49627578481335505 | Regularizer MSE: 0.057807472090576295 \n",
            "\t Val MSE: 0.5891375541687012 | Val MAE: 0.5678189396858215 \n",
            "Epoch: 73 | Train MSE: 0.5511534322645063\n",
            "\t Model MSE: 0.4933223523826243 | Regularizer MSE: 0.05783108023003997 \n",
            "\t Val MSE: 0.6033475995063782 | Val MAE: 0.5773036479949951 \n",
            "Epoch: 74 | Train MSE: 0.5450688773226515\n",
            "\t Model MSE: 0.4871072521276563 | Regularizer MSE: 0.0579616239416265 \n",
            "\t Val MSE: 0.5945978164672852 | Val MAE: 0.549740731716156 \n",
            "Epoch: 75 | Train MSE: 0.5397512890468134\n",
            "\t Model MSE: 0.48174794032194906 | Regularizer MSE: 0.05800334778483783 \n",
            "\t Val MSE: 0.5762946605682373 | Val MAE: 0.5501440763473511 \n",
            "Saving model...\n",
            "Epoch: 76 | Train MSE: 0.5473909029893786\n",
            "\t Model MSE: 0.4894039995759447 | Regularizer MSE: 0.05798690393567085 \n",
            "\t Val MSE: 0.5682967305183411 | Val MAE: 0.5578224658966064 \n",
            "Saving model...\n",
            "Epoch: 77 | Train MSE: 0.5413293515410379\n",
            "\t Model MSE: 0.48328680830581167 | Regularizer MSE: 0.05804254344412099 \n",
            "\t Val MSE: 0.5585541725158691 | Val MAE: 0.5497888326644897 \n",
            "Saving model...\n",
            "Epoch: 78 | Train MSE: 0.5383188607536744\n",
            "\t Model MSE: 0.48017721226282206 | Regularizer MSE: 0.05814164901308924 \n",
            "\t Val MSE: 0.5752677917480469 | Val MAE: 0.5553073287010193 \n",
            "Epoch: 79 | Train MSE: 0.5273264053268968\n",
            "\t Model MSE: 0.469259666505261 | Regularizer MSE: 0.05806673871718834 \n",
            "\t Val MSE: 0.5913702249526978 | Val MAE: 0.5578317046165466 \n",
            "Epoch: 80 | Train MSE: 0.5246214142469602\n",
            "\t Model MSE: 0.46649429174227136 | Regularizer MSE: 0.058127122713583654 \n",
            "\t Val MSE: 0.6072443127632141 | Val MAE: 0.5833844542503357 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrXjp-Nn-bop",
        "outputId": "b1ca79fe-448d-4d31-89db-6e61744e67c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "test_model = NCF(review_regularizer, num_users, num_items, num_factors=num_factors, num_layers=3).to(device)\n",
        "test_model.load_state_dict(torch.load(\"./model.pth\"))\n",
        "test_mse, test_mae = evaluate(data_loader=val_loader, model=test_model)\n",
        "print(\"test_mse\", test_mse)\n",
        "print(\"test_mae\", test_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_mse 0.5585541725158691\n",
            "test_mae 0.5497888326644897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdo_q0mZSjcR",
        "outputId": "6a86b7c8-30b3-4baa-c77f-dcf2fe2d1131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "print(\"Train MSE 1:\")\n",
        "print(losses1)\n",
        "print(\"Train MSE 2:\")\n",
        "print(losses2)\n",
        "print(\"Train MSE Overall:\")\n",
        "print(losses)\n",
        "print(\"Val MSE:\")\n",
        "print(val_mses)\n",
        "print(\"Val MAE:\")\n",
        "print(val_maes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train MSE 1:\n",
            "[6.975387682424527, 2.4478197632548966, 2.2390713836545144, 2.0929287237541696, 1.9537305486536471, 1.830698177079174, 1.6802593937544066, 1.5380160507754745, 1.4044613258860936, 1.3048175083142575, 1.252107774542871, 1.2220517926126997, 1.178480645206487, 1.1532885393249654, 1.130443045469088, 1.1176087811728503, 1.1029907682231654, 1.0985352179714452, 1.0881191820741813, 1.0822742391969555, 1.0817130319425994, 1.0750847169171984, 1.0714717278970736, 1.0625552585191815, 1.0566946000696342, 1.0413551999029713, 1.0277580451742512, 0.9920190143808026, 0.954094694039532, 0.9024516984681102, 0.8611442697382419, 0.8427348610396698, 0.8059221355714531, 0.784281529555811, 0.7658335839476541, 0.745366521527834, 0.7258392043202837, 0.7153672503533764, 0.6987694248417827, 0.6891251011429546, 0.6710373413897006, 0.6663967811058615, 0.6503953318172526, 0.637832385914348, 0.6350061077380849, 0.6206849381745418, 0.613675621625419, 0.6031197111740291, 0.5965623312464384, 0.5901018074739759, 0.5815238718674561, 0.5763352984022871, 0.5730111314871601, 0.5648417353073013, 0.5585670376492438, 0.5581592956436014, 0.5530455900686924, 0.5422610743580577, 0.5424564753737405, 0.5341119111698365, 0.533878516371005, 0.5265486073271136, 0.5284131442275003, 0.5160316362559239, 0.5182731917528348, 0.5129325336942049, 0.5111436370377228, 0.5093614679073619, 0.5056407560254926, 0.49517901645642576, 0.4900463042415191, 0.49627578481335505, 0.4933223523826243, 0.4871072521276563, 0.48174794032194906, 0.4894039995759447, 0.48328680830581167, 0.48017721226282206, 0.469259666505261, 0.46649429174227136]\n",
            "Train MSE 2:\n",
            "[1.2500631096207093, 0.9789149460391463, 0.8504611008635191, 0.7483939879408507, 0.6610953713131842, 0.5891527132453206, 0.5210524184681545, 0.4586625090826338, 0.4104299857237629, 0.36517222128181814, 0.3280314622081329, 0.293420840646619, 0.2642993207011267, 0.2386653275690346, 0.21719253216391413, 0.19649112893042164, 0.17889291591176362, 0.16366050482910371, 0.15076852346135078, 0.13911132173281965, 0.12818122808342783, 0.11837079529171791, 0.11089656314003134, 0.10407908643796066, 0.09758353442232186, 0.09161540134766391, 0.08654905556239814, 0.0819344750353109, 0.07886721904032698, 0.07579027011851285, 0.07276071924890314, 0.07000636810732778, 0.0682485779033643, 0.06645014077842792, 0.06553965563250479, 0.06394334687529324, 0.06265742665974894, 0.06156962256983062, 0.06096674341743238, 0.060541891536422976, 0.06019074727441663, 0.05940923589133771, 0.05910419846806571, 0.05852840245466366, 0.058586287721295226, 0.058244224463667824, 0.05830221160132194, 0.057987309748602806, 0.05762782289045994, 0.05787926376144463, 0.057987609825958714, 0.05761876200961175, 0.057649999299896094, 0.05748791759398496, 0.05756255322806189, 0.05773445949933239, 0.05752265028585898, 0.05759054436304859, 0.057616548734569104, 0.057613827218519195, 0.057694649236781574, 0.05783259443869101, 0.05759621025106617, 0.05771227309776244, 0.057717711464545435, 0.05765208145864656, 0.058031538762500355, 0.057717707808886735, 0.05795254098756291, 0.05792521365056528, 0.0579506744082286, 0.057807472090576295, 0.05783108023003997, 0.0579616239416265, 0.05800334778483783, 0.05798690393567085, 0.05804254344412099, 0.05814164901308924, 0.05806673871718834, 0.058127122713583654]\n",
            "Train MSE Overall:\n",
            "[8.225450836609458, 3.4267347193209923, 3.0895324889744553, 2.8413227228360753, 2.614825914953357, 2.419850898680286, 2.2013118222495107, 1.996678566264215, 1.814891314952173, 1.6699897251396536, 1.5801392348013192, 1.515472634930477, 1.4427799621475077, 1.3919538705148429, 1.3476355788863708, 1.314099914559694, 1.2818836865024033, 1.2621957214079171, 1.238887705535532, 1.2213855591889853, 1.2098942577281846, 1.1934555089362313, 1.1823682840739456, 1.1666343418237204, 1.1542781335171137, 1.132970599370582, 1.1143071021989128, 1.0739534870486394, 1.032961911687227, 0.9782419694918338, 0.9339049887434344, 0.9127412293558923, 0.8741707150067124, 0.8507316664000538, 0.8313732397890536, 0.8093098702831804, 0.7884966318852433, 0.7769368719831805, 0.7597361680503204, 0.749666995534273, 0.7312280881070645, 0.7258060167883044, 0.7094995304245815, 0.6963607874986167, 0.6935923951808537, 0.6789291634737888, 0.6719778336097146, 0.661107023464185, 0.6541901537191088, 0.6479810732547368, 0.6395114816237832, 0.6339540609689517, 0.6306611324582144, 0.6223296495241539, 0.6161295935929378, 0.615893755282197, 0.6105682393100774, 0.5998516183033168, 0.600073026440968, 0.5917257376920397, 0.5915731642847863, 0.5843812015569099, 0.5860093539563295, 0.5737439098759233, 0.5759909036003541, 0.5705846135861405, 0.5691751770884077, 0.5670791755769854, 0.563593296247108, 0.5531042301766226, 0.5479969775008264, 0.5540832573565367, 0.5511534322645063, 0.5450688773226515, 0.5397512890468134, 0.5473909029893786, 0.5413293515410379, 0.5383188607536744, 0.5273264053268968, 0.5246214142469602]\n",
            "Val MSE:\n",
            "[4.945785045623779, 4.141963958740234, 3.7900052070617676, 3.093989849090576, 2.810434341430664, 2.3693976402282715, 1.7685904502868652, 1.3876937627792358, 0.9880588054656982, 0.9180924892425537, 0.8951109051704407, 0.9112621545791626, 0.8592606782913208, 0.847967803478241, 0.8430925607681274, 0.8564801812171936, 0.8545507788658142, 0.834371030330658, 0.8554887175559998, 0.8140421509742737, 0.8501651287078857, 0.8214484453201294, 0.798393726348877, 0.7861762642860413, 0.7641263604164124, 0.7360013127326965, 0.7059879302978516, 0.6813992857933044, 0.6432083249092102, 0.618287980556488, 0.6130887269973755, 0.6046341061592102, 0.6265918612480164, 0.6147624850273132, 0.614460289478302, 0.5991323590278625, 0.6155586242675781, 0.6164273023605347, 0.6008410453796387, 0.6215294599533081, 0.6209113597869873, 0.6034937500953674, 0.6134670376777649, 0.6080309152603149, 0.6052803993225098, 0.6040730476379395, 0.6026767492294312, 0.5807170867919922, 0.5913578867912292, 0.589705228805542, 0.5886481404304504, 0.5932400226593018, 0.621451199054718, 0.6202796697616577, 0.6093278527259827, 0.6015082597732544, 0.6109474301338196, 0.6256759762763977, 0.6158613562583923, 0.604839563369751, 0.6163402795791626, 0.5951311588287354, 0.5907586812973022, 0.6031238436698914, 0.5948466658592224, 0.6067605018615723, 0.6095749139785767, 0.5978720188140869, 0.59902024269104, 0.5967841148376465, 0.6017123460769653, 0.5891375541687012, 0.6033475995063782, 0.5945978164672852, 0.5762946605682373, 0.5682967305183411, 0.5585541725158691, 0.5752677917480469, 0.5913702249526978, 0.6072443127632141]\n",
            "Val MAE:\n",
            "[2.0940771102905273, 1.9140702486038208, 1.8158149719238281, 1.62710440158844, 1.5310927629470825, 1.3854901790618896, 1.1972277164459229, 1.0631065368652344, 0.8407698273658752, 0.7980605363845825, 0.7903346419334412, 0.7951385378837585, 0.778643012046814, 0.7725636959075928, 0.7697544097900391, 0.7766483426094055, 0.7743322253227234, 0.7617273330688477, 0.7748112678527832, 0.7466973662376404, 0.7711141705513, 0.7541984915733337, 0.7338836193084717, 0.7284887433052063, 0.7125083804130554, 0.6742640733718872, 0.6826324462890625, 0.6621173024177551, 0.6139395236968994, 0.5995067954063416, 0.5718590617179871, 0.5599244832992554, 0.5868398547172546, 0.5647363066673279, 0.5830525755882263, 0.5568364858627319, 0.5753291249275208, 0.5609427094459534, 0.5522672533988953, 0.5909729599952698, 0.5866469144821167, 0.5415045619010925, 0.5651755332946777, 0.5699110627174377, 0.5482909083366394, 0.563805103302002, 0.5695282220840454, 0.5454156398773193, 0.5491566061973572, 0.5546334981918335, 0.5464099049568176, 0.548762321472168, 0.5693340301513672, 0.5407211780548096, 0.5555150508880615, 0.5480301976203918, 0.5608841776847839, 0.565136730670929, 0.5491747856140137, 0.5387365818023682, 0.5481396317481995, 0.5508458614349365, 0.5483571290969849, 0.5610043406486511, 0.5498717427253723, 0.554466962814331, 0.5589249730110168, 0.560016393661499, 0.5600225925445557, 0.5651541352272034, 0.5624216794967651, 0.5678189396858215, 0.5773036479949951, 0.549740731716156, 0.5501440763473511, 0.5578224658966064, 0.5497888326644897, 0.5553073287010193, 0.5578317046165466, 0.5833844542503357]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}